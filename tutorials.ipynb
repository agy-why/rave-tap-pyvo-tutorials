{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* [Installation of pyvo](#Installation-of-pyvo)\n",
    "* [Importing PyVo and checking the version](#Importing-PyVo-and-checking-the-version)\n",
    "* [Authentication](#Authentication)\n",
    "* [Short (synchronous) queries](#Short-queries)\n",
    "* [Asynchronous jobs](#Asynchronous-jobs)\n",
    "    * [The 60 seconds queue](#The-60-seconds-queue)\n",
    "    * [The 30 minutes queue](#The-30-minutes-queue)\n",
    "* [Submitting multiple queries](#Submitting-multiple-queries)\n",
    "    * [Your query is too long? Chunk it!](#Your-query-is-too-long?-Chunk-it!)\n",
    "    * [List of file queries](#List-of-file-queries)\n",
    "* [Convert to various python types](#Convert-to-various-python-types)\n",
    "* [Automatically downloading files from path results](#Automatically-downloading-files-from-path-results)\n",
    "* [Archiving your jobs](#Archiving-your-jobs)\n",
    "    * [Archiving all COMPLETED jobs](#Archiving-all-COMPLETED-jobs)\n",
    "    * [Rerunning ARCHIVED jobs](#Rerunning-ARCHIVED-jobs)\n",
    "\n",
    "\n",
    "# Installation of pyvo\n",
    "---\n",
    "\n",
    "In order to interact with the TAP interface of `rave-survey.org` you only require\n",
    "`python 3+` and `pyvo 1+`.\n",
    "\n",
    "```bash\n",
    "pip install pyvo>=1.0\n",
    "```\n",
    "\n",
    "# Importing PyVo and checking the version\n",
    "---\n",
    "\n",
    "It is useful to always print the version of pyvo you are using. Most of non-working scripts fail because of an old version of `pyvo`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources import parse_version\n",
    "import pyvo\n",
    "\n",
    "#\n",
    "# Verify the version of pyvo\n",
    "#\n",
    "if parse_version(vo.__version__) < parse_version('1.0'):\n",
    "    raise ImportError('pyvo version must be at least than 1.0')\n",
    "\n",
    "print('\\npyvo version {} \\n'.format(vo.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication\n",
    "---\n",
    "\n",
    "After registration you can access your API Token by clicking on your user name in the right side of the menu bar. Then select `API Token`. \n",
    "\n",
    "![api-token](files/API_rave_Token_screenshot.png)\n",
    "\n",
    "You will see a long alphanumerical word. Just copy it where ever you see `<your-token>` ; in the following examples. \n",
    "\n",
    "![api-token-blured](files/API_rave_Token_blured.png)\n",
    "\n",
    "> **The `API Token` identifies you and provides access to the results tables of your queries.**\n",
    "\n",
    "The connection to the TAP service can be done that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyvo\n",
    "\n",
    "#\n",
    "# Setup tap_service\n",
    "#\n",
    "service_name = 'rave-survey.org'\n",
    "url = \"https://www.rave-survey.org/tap\"\n",
    "token = 'Token <your-token>'\n",
    "\n",
    "print('TAP service {} \\n'.format(service_name))\n",
    "\n",
    "# Setup authorization\n",
    "tap_session = requests.Session()\n",
    "tap_session.headers['Authorization'] = token\n",
    "\n",
    "tap_service = vo.dal.TAPService(url, session=tap_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short queries\n",
    "---\n",
    "\n",
    "Many queries last less than a few seconds, we call them **short queries**. The latter can be executed with **synchronized** jobs. You will retrieve the results interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'PostgreSQL'\n",
    "\n",
    "query = '''\n",
    "SELECT raveid, radeg, dedeg\n",
    "FROM \"ravedr4\".\"rave_dr4\"\n",
    "  LIMIT 100;\n",
    "'''\n",
    "\n",
    "tap_result = tap_service.run_sync(query, language=lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Remark**:\n",
    "> the `lang` parameter can take two values either `PostgreSQL` or `ADQL`\n",
    "> this allows to access some featured present in the one or the other language \n",
    "> for more details about the difference ebtween both please refer : [FAQ](https://gaia.aip.de/cms/documentation/faq/snagsftu1/), [Blog](https://gaia.aip.de/cms/adql-queries-in-the-interface/), [Documentation](http://tapvizier.u-strasbg.fr/adql/help.html) or to [IOVA docs](http://www.ivoa.net/documents/latest/ADQL.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result `tap_result` is a so called [`TAPResults`](https://pyvo.readthedocs.io/en/latest/api/pyvo.dal.TAPResults.html#pyvo.dal.TAPResults) that is essentially a wrapper around an Astropy `votable.Table`. For standard conversion see [Convert to various python types](#convertion).\n",
    "\n",
    "The entire script can be found on github: [rave-tutorial-sync-job.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-sync-job.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous jobs\n",
    "---\n",
    "\n",
    "For slightly longer queries, typically counting or larger selections (>10000 objects) a synchronized job will fail because of timeouts (from http protocol or server settings). This is why we provide the possibility to submit **asynchronous** jobs. These type of jobs will run on the server side, store the results such that you can retrieve them at a later time. They come in two flavors:\n",
    "* 60 seconds queue\n",
    "* 30 minutes queue\n",
    "\n",
    "\n",
    "## The 60 seconds queue\n",
    "\n",
    "Most of the asynchronous queries will require less than 60 seconds, basically all queries without `JOIN`, or `CONE SEARCH`. Therefore this queue is the default and should be preferred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Submit the query as an async job\n",
    "#\n",
    "query_name = \"multi_dr3\"\n",
    "lang = 'PostgreSQL'\n",
    "\n",
    "query = '''\n",
    "-- Multiple observations in DR3\n",
    "\n",
    "SELECT F.raveid, F.radeg, F.dedeg, T.N \n",
    "FROM \n",
    "    ( SELECT raveid, count(*) AS N \n",
    "      FROM ravedr3.rave_dr3a \n",
    "          GROUP BY raveid\n",
    "          HAVING count(*) > 1 \n",
    "          ORDER BY N DESC ) T JOIN ravedr3.rave_dr3a F \n",
    "    ON F.raveid = T.raveid\n",
    "'''\n",
    "\n",
    "job = tap_service.submit_job(query, language=lang, runid=query_name, queue=\"60s\")\n",
    "job.run()\n",
    "\n",
    "#\n",
    "# Wait to be completed (or an error occurs)\n",
    "#\n",
    "job.wait(phases=[\"COMPLETED\", \"ERROR\", \"ABORTED\"], timeout=60.)\n",
    "print('JOB {name}: {status}'.format(name=job.job.runid , status=job.phase))\n",
    "\n",
    "#\n",
    "# Fetch the results\n",
    "#\n",
    "job.raise_if_error()\n",
    "print('\\nfetching the results...')\n",
    "tap_results = job.fetch_result()\n",
    "print('...DONE\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for sync jobs, the result is a [`TAPResults`](https://pyvo.readthedocs.io/en/latest/api/pyvo.dal.TAPResults.html#pyvo.dal.TAPResults) object.\n",
    "\n",
    "The entire script can be found on gihub: [rave-tutorial-async-60s.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-async-60s.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The 30 minutes queue\n",
    "\n",
    "Some complex queries like Cross-Matching or geometric search may take more than 60 seconds. For this purpose we provide the **30 minutes queue**. If you need longer queue please contact us. \n",
    "\n",
    "When running a long query, you surely don't want to block CPU ressources for a python process that just wait for two hours, for the queue to finish. Therefore long queries are typically done in two parts (= two scripts), one that submits the request, another one that retrieve the results.\n",
    "\n",
    "### Submitting a job and store `job_urls` for later retrieval\n",
    "\n",
    "We first submit the query as an async job to the `30m` queue, and store the job (the url) of the newly created job into a file `job_url.txt`. With this url we are able to retrieve the results (after it's finished) at any later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Submit the query as an async job\n",
    "#\n",
    "query_name = \"multi_dr3\"\n",
    "lang = 'PostgreSQL'\n",
    "\n",
    "query = '''\n",
    "-- Multiple observations in DR3\n",
    "\n",
    "SELECT F.raveid, F.radeg, F.dedeg, T.N \n",
    "FROM \n",
    "    ( SELECT raveid, count(*) AS N \n",
    "      FROM ravedr3.rave_dr3a \n",
    "          GROUP BY raveid\n",
    "          HAVING count(*) > 1 \n",
    "          ORDER BY N DESC ) T JOIN ravedr3.rave_dr3a F \n",
    "    ON F.raveid = T.raveid\n",
    "'''\n",
    "\n",
    "job = tap_service.submit_job(query, language=lang, runid=query_name, queue=\"30m\")\n",
    "job.run()\n",
    "\n",
    "print('JOB {name}: SUBMITTED'.format(name=job.job.runid))\n",
    "print('JOB {name}: {status}'.format(name=job.job.runid , status=job.phase))\n",
    "\n",
    "#\n",
    "# Save the job's url in a file to later retrieve results.\n",
    "#\n",
    "print('URL: {}'.format(job.url))\n",
    "\n",
    "with open('job_url.txt', 'w') as fd:\n",
    "    fd.write(job.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the results at a later time\n",
    "\n",
    "In order to retrieve the results, we will first recreate the job from the `job_url` stored in the `job_url.txt` file and verify that the job is finished, by asking for its current phase. In case the job is finished we will retrieve the results as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Recreate the job from url and session (token)\n",
    "#\n",
    "\n",
    "# read the url\n",
    "with open('job_url.txt', 'r') as fd:\n",
    "    job_url = fd.readline()\n",
    "\n",
    "# recreate the job \n",
    "job = AsyncTAPJob(job_url, session=tap_session)\n",
    "\n",
    "#\n",
    "# Check the job status\n",
    "#\n",
    "print('JOB {name}: {status}'.format(name=job.job.runid , status=job.phase))\n",
    "\n",
    "# if still running --> exit\n",
    "if job.phase not in (\"COMPLETED\", \"ERROR\", \"ABORTED\"):\n",
    "    exit(0)\n",
    "\n",
    "#\n",
    "# Fetch the results\n",
    "#\n",
    "job.raise_if_error()\n",
    "print('\\nfetching the results...')\n",
    "tap_results = job.fetch_result()\n",
    "print('\\n...DONE\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to this method you can submit a job, go for a coffee, write a paper and retrieve the results \n",
    "when it suits you. The job and its results are stored on the server side under your user account.\n",
    "\n",
    "The entire scripts can be found on github: [rave-tutorial-submit-30m.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-submit-30m.py) and [rave-tutorial-retrieve-30m.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-retrieve-30m.py)\n",
    "\n",
    "# Submitting multiple queries\n",
    "\n",
    "Some time it is needed to submit several queries at one time. Either because the entire query may last longer than 30 minutes and you need to cut it in smaller parts, or because you need non `JOIN`-able information from various tables.\n",
    "\n",
    "## Your query is too long? Chunk it!\n",
    "\n",
    "Before contacting us and ask for longer queue time: You may try to cut the long query into chunks, and execute your long query as a list of shorter queries. \n",
    "\n",
    "There are two typical way to do it:\n",
    "* cut it with `LIMIT` and `OFFSET`\n",
    "* filter it with `WHERE`\n",
    "\n",
    "Let us concider this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query = '''\n",
    "-- Get objects with radial velocites within a range (DR4) \n",
    "\n",
    "SELECT * \n",
    "FROM ravedr4.rave_dr4\n",
    "  WHERE hrv\n",
    "    BETWEEN 5.0 AND 25.0 \n",
    "  ORDER BY hrv DESC\n",
    "  '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add `LIMIT` and `OFFSET` in order to cut the request in shorter parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query = '''\n",
    "-- Get objects with radial velocites within a range (DR4) \n",
    "\n",
    "SELECT * \n",
    "FROM ravedr4.rave_dr4\n",
    "  WHERE hrv\n",
    "    BETWEEN 5.0 AND 25.0 \n",
    "  ORDER BY hrv DESC\n",
    "  \n",
    "  LIMIT {limit} OFFSET {offset}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use it the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of failed jobs\n",
    "failed = []\n",
    "\n",
    "#\n",
    "# Submit queries\n",
    "#\n",
    "base_name = 'hrv_{index}'\n",
    "lang = 'PostgreSQL'\n",
    "\n",
    "base_query = '''\n",
    "-- Get objects with radial velocites within a range (DR4) \n",
    "\n",
    "SELECT * \n",
    "FROM ravedr4.rave_dr4\n",
    "  WHERE hrv\n",
    "    BETWEEN 5.0 AND 25.0 \n",
    "  ORDER BY hrv DESC\n",
    "  \n",
    "  LIMIT {limit:d} OFFSET {offset:d}\n",
    "'''\n",
    "\n",
    "limit = 1000\n",
    "total = 10000\n",
    "index = 0\n",
    "\n",
    "# open the file to store the jobs\n",
    "fd = open('jobs_url.txt', 'w')\n",
    "\n",
    "# header \n",
    "print('          {: ^{name_width}} -- limit : offset'.format('name', name_width=len(base_name)-6))\n",
    "\n",
    "for offset in range(0, total, limit):\n",
    "\n",
    "    query = base_query.format(limit=limit, offset=offset)\n",
    "    name = base_name.format(index=index)\n",
    "\n",
    "    print('> Query : {name} -- {limit}:{offset}'.format(name=name, limit=limit, offset=offset))\n",
    "\n",
    "    # Create the async job\n",
    "    try:\n",
    "        job = tap_service.submit_job(query, language=lang, runid=name, queue=\"30m\")\n",
    "    except Exception as e:\n",
    "        print('ERROR could not create the job.')\n",
    "        print(e)\n",
    "        failed.append(runid)\n",
    "        continue\n",
    "\n",
    "    # Run the run\n",
    "    try:\n",
    "        job.run()\n",
    "    except Exception as e:\n",
    "        print('Error: could not run the job. Are you sure about your SQL query? Wrong language?')\n",
    "        print(e)\n",
    "        failed.append(name)\n",
    "        continue\n",
    "\n",
    "    # Save the submitted jobs into a file\n",
    "    fd.write(job.url + '\\n')\n",
    "    index = index + 1\n",
    "\n",
    "# Verify that all jobs have been submitted\n",
    "try:\n",
    "    assert(failed == [])\n",
    "except AssertionError:\n",
    "    print(\"The following jobs had failed: {jobs}\".format(failed))\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the results is similar to the single query version above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_results = []\n",
    "running_job_names = []\n",
    "\n",
    "#\n",
    "# Recreate the job from url and session (token)\n",
    "#\n",
    "\n",
    "# read the url\n",
    "with open('jobs_url.txt', 'r') as fd:\n",
    "    job_urls = fd.readlines()\n",
    "\n",
    "# reopen the file to store the non finished jobs\n",
    "fd = open('jobs_url.txt', 'w')\n",
    "\n",
    "for job_url in job_urls:\n",
    "\n",
    "    # recreate the job \n",
    "    job = AsyncTAPJob(job_url, session=tap_session)\n",
    "\n",
    "    #\n",
    "    # Check the job status\n",
    "    #\n",
    "    print('JOB {name}: {status}'.format(name=job.job.runid , status=job.phase))\n",
    "\n",
    "    # if still running --> exit\n",
    "    if job.phase not in (\"COMPLETED\", \"ERROR\", \"ABORTED\"):\n",
    "        running_job_names.append(job.job.runid)\n",
    "        fd.write(job_url)\n",
    "        continue\n",
    "\n",
    "    #\n",
    "    # Fetch the results\n",
    "    #\n",
    "    job.raise_if_error() # This need to be caught!!\n",
    "    print('fetching the results...\\n')\n",
    "    partial_results.append(job.fetch_result())\n",
    "    \n",
    "print('...DONE\\n')\n",
    "\n",
    "try:\n",
    "    assert(running_job_names == [])\n",
    "except AssertionError:\n",
    "    print(\"The following jobs are still executing: {}\".format(running_job_names))\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire scripts can be found on gihub: [rave-tutorial-submit-multi.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-submit-multi.py) and [rave-tutorial-retrieve-multi.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-retrieve-multi.py)\n",
    "\n",
    "## List of file queries\n",
    "\n",
    "Sometimes it is useful to just send all `.sql` queries present in a directory. For such purpose you can use comments to provide the proper parameters.\n",
    "\n",
    "Let us consider the file `rave-example03.sql`\n",
    "\n",
    "```sql\n",
    "-- Count the number of objects in the RAVE DR4 database\n",
    "\n",
    "-- LANGUAGE = PostgreSQL\n",
    "-- QUEUE = 60s\n",
    "\n",
    "SELECT count(*)\n",
    "FROM \"ravedr4\".\"rave_dr4\";\n",
    "```\n",
    "\n",
    "The `language` and `queue` are prescibed as comments. The query can then be submitted in a script like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "#\n",
    "# Submit the query as an Asynchrone job\n",
    "#\n",
    "\n",
    "# find all .sql files in current directory\n",
    "queries_filename = sorted(glob.glob('./*.sql'))\n",
    "print('Sending {n} examples'.format(n=len(queries_filename)))\n",
    "\n",
    "# initialize test results\n",
    "jobs = []\n",
    "failed =  []\n",
    "\n",
    "# send all queries\n",
    "for query_filename in queries_filename:\n",
    "\n",
    "    # read the .SQL file\n",
    "    with open(query_filename, 'r') as fd:\n",
    "        query = ' '.join(fd.readlines())\n",
    "\n",
    "    # Set language from comments (default: PostgreSQL)\n",
    "    if 'LANGUAGE = ADQL' in query:\n",
    "        lang = 'ADQL'\n",
    "    else:\n",
    "        lang = 'PostgreSQL'\n",
    "\n",
    "    # Set queue from comments (default: 60s)\n",
    "    if 'QUEUE = 30m' in query:\n",
    "        queue = \"30m\"\n",
    "    else:\n",
    "        queue = \"60s\"\n",
    "\n",
    "    # Set the runid from sql filename\n",
    "    base = os.path.basename(query_filename)\n",
    "    runid = os.path.splitext(base)[0]\n",
    "    \n",
    "    print('\\n> Query : {name}\\n{query}\\n'.format(name=runid, query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the submission process and retrieval can be done in any manner. An example \n",
    "can be found on github: [rave-tutorial-from-files.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-from-files.py)\n",
    "\n",
    "# Convert result to various python types\n",
    "\n",
    "The results obtained via the `fetch_results()` method returns a so called `TAPResults` object. The latter is essencially a `votable`. In case you are not familiar with `votables` here is a few tricks to get back to some more general pythonic types.\n",
    "\n",
    "* Print the data:\n",
    "  ```python\n",
    "  tap_results.to_table().pprint(max_lines=10)\n",
    "  ```\n",
    "  It is important to notice the `max_lines` keyword, printing too many lines may crash a low-memory machine.\n",
    "  \n",
    "* Show as html (in a browser):\n",
    "  ```python\n",
    "  tap_results.to_table().show_in_browser(max_lines=10)\n",
    "  ```\n",
    "  It is important to notice the `max_lines` keyword, printing too many lines may crash a low-memory machine.\n",
    "  \n",
    "* Show in a notebook (ipython, jupyter or jupyterlab):\n",
    "  ```python\n",
    "  tap_results.to_table().show_in_notebook(display_length=10)\n",
    "  ```\n",
    "  It is important to notice the `display_length` keyword, printing too many lines may crash a low-memory machine.\n",
    "  \n",
    "* Get a numpy array:\n",
    "  ```python\n",
    "  np_array = tap_results.to_table().as_array()\n",
    "  ```\n",
    "  \n",
    "* Get a Panda's DataFrame\n",
    "    ```python\n",
    "    df = tap_results.to_table().to_pandas()\n",
    "    ```\n",
    "    \n",
    "    * Get the header of DataFrame:\n",
    "        ```python\n",
    "        df.head()\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically downloading files from path results\n",
    "\n",
    "Some queries do not return `data` but the `urls` of the files where the data are stored ; examples are spectras, or images. When your query returns a few file-paths it is possible to download them by hand, however it is usually more practical to download them automaticaly. Here is an example using pure python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Automatically downloading files\n",
    "#\n",
    "\n",
    "#\n",
    "# Query the fits files\n",
    "#\n",
    "lang = \"PostgreSQL\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT spectrum_fits \n",
    "FROM ravedr6.dr6_spectra \n",
    "  WHERE rave_obs_id LIKE '200304%' \n",
    "\"\"\"\n",
    "\n",
    "# Submit the query as Synchronous job\n",
    "tap_result = tap_service.run_sync(query, language=lang)\n",
    "path_to_fits = tap_result.to_table()\n",
    "\n",
    "#\n",
    "# Download the fits files into local directory\n",
    "#\n",
    "target_directory = './fits/'\n",
    "fit_file_base_url = 'https://www.rave-survey.org/files/'\n",
    "\n",
    "for fit_file in path_to_fits:\n",
    "    \n",
    "    # extract name of the fits\n",
    "    fit_name = os.path.basename(fit_file[0])\n",
    "    \n",
    "    # set the target local file\n",
    "    fit_file_name = os.path.join(target_directory, fit_name)\n",
    "    \n",
    "    # build the url pointing to the fit file\n",
    "    fit_file_url = os.path.join(fit_file_base_url, fit_file[0])\n",
    "    \n",
    "    # download and save into target file\n",
    "    print(\"Downloaded {fitfile} into {target}\".format(fitfile=fit_name, target=fit_file_name))\n",
    "    urllib.request.urlretrieve(fit_file_url, fit_file_name)\n",
    "    \n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archiving your jobs\n",
    "\n",
    "If you submit several large queries you may go over quota: set to 10 GB. In order to avoid to get over quota you may consider archiving your jobs. Archiving removes the data from the server side but keeps the SQL query. This allows to resubmit a query at a later time.\n",
    "\n",
    "Deleting (archiving) a job with pyvo can be simply done that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archiving all COMPLETED jobs\n",
    "\n",
    "A nice feature of the TAP service is to retrieve all jobs that are marked as completed and archive them at ones. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Archiving all COMPLETED jobs\n",
    "#\n",
    "\n",
    "# obtain the list of completed job_descriptions\n",
    "completed_job_descriptions = tap_service.get_job_list(phases='COMPLETED')\n",
    "\n",
    "# Archiving each of them\n",
    "for job_description in completed_job_descriptions:\n",
    "    \n",
    "    # get the jobid\n",
    "    jobid = job_description.jobid\n",
    "    \n",
    "    # recreate the url by hand\n",
    "    job_url = tap_service.baseurl + '/async/' + jobid\n",
    "    \n",
    "    # recreate the job\n",
    "    job = AsyncTAPJob(job_url, session=tap_session)\n",
    "    \n",
    "    print('Archiving: {url}'.format(url=job_url))\n",
    "    job.delete() # archive job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example can be found on github: [rave-tutorial-archive-jobs.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-archive-jobs.py)\n",
    "\n",
    "## Rerunning ARCHIVED jobs\n",
    "\n",
    "Rerunning and retrieving results from a job that have been archived previously, can be achieved that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Rerunning Archived jobs\n",
    "#\n",
    "\n",
    "# obtain the list of the two last ARCHIVED job_descriptions\n",
    "archived_job_descriptions = tap_service.get_job_list(phases='ARCHIVED', last=2)\n",
    "\n",
    "# rerunning the two last Archived jobs\n",
    "for job_description in archived_job_descriptions:\n",
    "    \n",
    "    # get jobid\n",
    "    jobid = job_description.jobid\n",
    "    \n",
    "    # recreate the url by hand\n",
    "    job_url = tap_service.baseurl + '/async/' + jobid\n",
    "    \n",
    "    # recreate the archived job\n",
    "    archived_job = AsyncTAPJob(job_url, session=tap_session)\n",
    "    \n",
    "    # extract the query\n",
    "    query = archived_job.query\n",
    "    \n",
    "    # resubmit the query with corresponding parameters\n",
    "    job = tap_service.submit_job(query, language='PostgreSQL', runid='rerun', queue='60s')\n",
    "    print('{url}:\\n{query}\\n'.format(url=job_url, query=query))\n",
    "    \n",
    "    # start the job\n",
    "    job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the results is done alike explained above.\n",
    "\n",
    "If you prefer you can also filter for a given `runid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Filtering by runid\n",
    "#\n",
    "\n",
    "target_runid = 'rave-example03'\n",
    "\n",
    "# obtain the list of completed job_descriptions\n",
    "archived_job_descriptions = tap_service.get_job_list(phases='ARCHIVED')\n",
    "\n",
    "for job_description in archived_job_descriptions:\n",
    "    \n",
    "    # select the job with runid fitting target_runid\n",
    "    if job_description.runid == target_runid:\n",
    "        \n",
    "        # get jobid\n",
    "        jobid = job_description.jobid\n",
    "    \n",
    "        # recreate the url by hand\n",
    "        job_url = tap_service.baseurl + '/async/' + jobid\n",
    "    \n",
    "        # recreate the archived job\n",
    "        archived_job = AsyncTAPJob(job_url, session=tap_session)\n",
    "    \n",
    "        # extract the query\n",
    "        query = archived_job.query\n",
    "    \n",
    "        # resubmit the query with corresponding parameters\n",
    "        job = tap_service.submit_job(query, language='PostgreSQL', runid='rerun', queue='60s')\n",
    "        print('{url}:\\n{query}\\n'.format(url=job_url, query=query))\n",
    "    \n",
    "        # start the job\n",
    "        job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example can be found on github: [rave-tutorial-rerunning-archived-jobs.py](https://github.com/agy-why/rave-tap-pyvo-tutorials/blob/master/rave-tutorial-rerunning-archived-jobs.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
